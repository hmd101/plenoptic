{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from typing import List, Tuple, Union, Callable, Optional\n",
    "import plenoptic as po\n",
    "import pyrtools as pt\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../tools/')\n",
    "from plenoptic.tools import img_transforms \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path= '../../../../../ceph/Datasets/select_color_textures_unsplash'\n",
    "save_path = '../../../../../ceph/experiments/color_texture_synth'\n",
    "# Function to load and preprocess images\n",
    "def load_and_reshape_images(image_path: str) -> torch.Tensor:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    images = []\n",
    "    for filename in glob.glob(os.path.join(image_path, '*.jpg')):  \n",
    "        img = Image.open(filename).convert('RGB')\n",
    "        img = transform(img)\n",
    "        img = img_transforms.rgb_to_opponentcone(img)\n",
    "        images.append(img)\n",
    "    print(\"Images loaded and preprocessed.\")\n",
    "    return torch.stack(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images loaded and preprocessed.\n"
     ]
    }
   ],
   "source": [
    "images = load_and_reshape_images(image_path)\n",
    "#images[0].shape[-1].to_numpy()\n",
    "# convert an int to a numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_and_preprocess_images(images: torch.Tensor) -> torch.Tensor:\n",
    "    img_transforms.rgb_to_opponentcone(images)\n",
    "    # Rescale images to [0, 1]\n",
    "    images = images - images.min()\n",
    "    images = images / images.max()\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_rescale_and_transform(images: torch.Tensor) -> List[Image.Image]:\n",
    "    rgb_images = img_transforms.opponentcone_to_rgb(images)\n",
    "    rgb_images = [transforms.ToPILImage()(img) for img in rgb_images]\n",
    "    print(\"Inverse rescale and transform complete.\")\n",
    "    return rgb_images\n",
    "\n",
    "\n",
    "# Main function to run synthesis and save images\n",
    "def main(model_name: str,max_iter: int = 10,init_image = None, \n",
    "        ctf_iters_to_check: int = 3, loss_function = po.tools.optim.l2_channelwise, coarse_to_fine: str = 'together', image_path: str = '../../../../../ceph/Datasets/select_color_textures_unsplash',save_path: str = '../../../../../ceph/experiments/color_texture_synth',):\n",
    "    \n",
    "    # TODO: Add these arguments from portillasimoncelli constructor:  \n",
    "    #n_scales: int = 4,\n",
    "    #n_orientations: int = 4,\n",
    "    #spatial_corr_width: int = 9\n",
    "    # crosschannel covariance\n",
    "    images = load_and_reshape_images(image_path)\n",
    "    images = rescale_and_preprocess_images(images)\n",
    "    if init_image is None:\n",
    "        init_image = torch.rand_like(images) * .01 + images.mean()\n",
    "\n",
    "\n",
    "    model = model_name(images[0,0,:,:].shape)\n",
    "\n",
    "    metamer = po.synth.MetamerCTF(\n",
    "        image=images,\n",
    "        model=model, \n",
    "        loss_function=loss_function, \n",
    "        initial_image=init_image, \n",
    "        coarse_to_fine=coarse_to_fine\n",
    "    )\n",
    "    \n",
    "    metamer.synthesize(max_iter=max_iter, store_progress=True,\n",
    "        change_scale_criterion=None, ctf_iters_to_check=ctf_iters_to_check)\n",
    "    print(\"Synthesis complete.\")\n",
    "    # TODO get correct metamer attribute\n",
    "    synthesized_images = metamer.metamer\n",
    "    \n",
    "    rgb_images = inverse_rescale_and_transform(synthesized_images)\n",
    "    \n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "        print(f\"Created directory {save_path}\")\n",
    "    \n",
    "    for i, img in enumerate(rgb_images):\n",
    "        print(f\"Saving image {i}\")\n",
    "        save_filename = f\"{ctf_iters_to_check}_{model_name}_{max_iter}.png\"\n",
    "        img.save(os.path.join(save_path, save_filename))\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     import argparse\n",
    "#     # path to the data: /mnt/home/hdettki/ceph/Datasets/select_color_textures_unsplash\n",
    "#     # path to color script: /mnt/home/hdettki/code/plenoptic/src/plenoptic/synthesize\n",
    "#     parser = argparse.ArgumentParser(description=\"Run image synthesis with specified parameters.\")\n",
    "#     parser.add_argument(\"--image_path\", type=str, required=False, default= '../../../../../ceph/Datasets/select_color_textures_unsplash',help=\"Path to the input images.\")\n",
    "#     parser.add_argument(\"--save_path\", type=str, required=False,default='../../../../../ceph/experiments/color_texture_synth', help=\"Path to save the output images.\")\n",
    "#     parser.add_argument(\"--model_name\", type=str, required=True, help=\"Model to be used.\")\n",
    "#     #parser.add_argument(\"--loss_function\", type=str, required=False, help=\"Loss function to be used. Recommended: l2channelwise in po.tools.optim\")\n",
    "#     #parser.add_argument(\"--init_image\", type=None, required=False, help=\"Initial image for synthesis.\")\n",
    "#     parser.add_argument(\"--coarse_to_fine\", type=bool, default=False, help=\"Use coarse to fine synthesis.\")\n",
    "#     parser.add_argument(\"--max_iter\", type=int, required=False,default=300, help=\"Maximum number of iterations. If GPU available, use > 3000.\")\n",
    "#     parser.add_argument(\"--ctf_iters_to_check\", type=int, nargs='+', required=False,default=3, help=\"Iterations to check in coarse to fine synthesis.\")\n",
    "    \n",
    "\n",
    "#     args = parser.parse_args()\n",
    "    \n",
    "    # main(\n",
    "    #     image_path=args.image_path, \n",
    "    #     save_path=args.save_path, \n",
    "    #     model_name=getattr(po.simul, args.model_name), \n",
    "    #     #loss_function=getattr(po.tools.optim, args.loss_function), \n",
    "    #     #init_image=torch.load(args.init_image) if args.init_image else None, \n",
    "    #     coarse_to_fine=args.coarse_to_fine, \n",
    "    #     max_iter=args.max_iter, \n",
    "    #     ctf_iters_to_check=args.ctf_iters_to_check\n",
    "    # )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images loaded and preprocessed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/hdettki/code/plenoptic/src/plenoptic/tools/validate.py:178: UserWarning: model is in training mode, you probably want to call eval() to switch to evaluation mode\n",
      "  warnings.warn(\n",
      "/mnt/home/hdettki/code/plenoptic/src/plenoptic/tools/validate.py:211: UserWarning: Validating whether model can work with coarse-to-fine synthesis -- this can take a while!\n",
      "  warnings.warn(\"Validating whether model can work with coarse-to-fine synthesis -- this can take a while!\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e786dc75063495ebff2a024f814de05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesis complete.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MetamerCTF' object has no attribute 'synthesized_image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimul\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPortillaSimoncelliCrossChannel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctf_iters_to_check\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 36\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(model_name, max_iter, init_image, ctf_iters_to_check, loss_function, coarse_to_fine, image_path, save_path)\u001b[0m\n\u001b[1;32m     33\u001b[0m metamer\u001b[38;5;241m.\u001b[39msynthesize(max_iter\u001b[38;5;241m=\u001b[39mmax_iter, store_progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     34\u001b[0m     change_scale_criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ctf_iters_to_check\u001b[38;5;241m=\u001b[39mctf_iters_to_check)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSynthesis complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m synthesized_images \u001b[38;5;241m=\u001b[39m \u001b[43mmetamer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynthesized_image\u001b[49m\n\u001b[1;32m     38\u001b[0m rgb_images \u001b[38;5;241m=\u001b[39m inverse_rescale_and_transform(synthesized_images)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(save_path):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MetamerCTF' object has no attribute 'synthesized_image'"
     ]
    }
   ],
   "source": [
    "main(po.simul.PortillaSimoncelliCrossChannel, max_iter=10, ctf_iters_to_check=3, image_path=image_path, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plenoptic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
